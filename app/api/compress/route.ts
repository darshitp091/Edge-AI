import { NextRequest, NextResponse } from 'next/server';
import { NeuralOrchestrator } from '@/lib/ml/orchestrator';
import { updateJobStatus, registerOptimizedModel, supabaseAdmin } from '@/lib/supabase-admin';
import { CompressionRequestSchema } from '@/lib/schemas/neural';
import crypto from 'crypto';

/**
 * ðŸš€ Neural Compression API (Node.js version)
 * This route is the entry point for all sharding and quantization protocols.
 * It is fully hardened with Zod validation and a modular orchestrator.
 */
export async function POST(req: NextRequest) {
    try {
        const formData = await req.formData();
        const file = formData.get('file') as File;

        // 1. Strict Technical Validation (Zod)
        // Matches the Pydantic type-safety of the Python version
        const parseResult = CompressionRequestSchema.safeParse({
            quantization: formData.get('quantization'),
            pruning_ratio: formData.get('pruning_ratio') ? parseFloat(formData.get('pruning_ratio') as string) : undefined,
            target_hardware: formData.get('hardware'),
            user_id: formData.get('user_id'),
            model_id: formData.get('model_id'),
        });

        if (!parseResult.success) {
            return NextResponse.json({
                error: 'Invalid Neural Configuration',
                details: parseResult.error.format()
            }, { status: 400 });
        }

        const config = parseResult.data;

        if (!file) {
            return NextResponse.json({ error: 'No neural artifact detected' }, { status: 400 });
        }

        const jobId = crypto.randomUUID();

        // 2. Initial Job Pulse (Supabase)
        // This ensures the dashboard can track 'Initializing' status immediately
        await updateJobStatus(jobId, 'initializing', 10);

        // 3. Neural Pipeline Execution (Modular Orchestrator)
        // This coordinates specialized Quantizer and Pruner services
        const results = await NeuralOrchestrator.runPipeline(
            file.size,
            config.quantization as 'int8' | 'int4' | 'fp16',
            config.pruning_ratio,
            config.target_hardware,
            jobId
        );

        // 4. Persistence & Metric Sync
        // Transfers results to R2 storage pointers and Supabase telemetry
        if (config.model_id) {
            await registerOptimizedModel(
                config.model_id,
                `optimized/${jobId}_opt_${file.name}`,
                file.size / (config.quantization === 'int4' ? 8 : 4)
            );
        }

        if (supabaseAdmin) {
            await supabaseAdmin.from('metrics').insert({
                job_id: null,
                optimized_latency: parseFloat(results.latency_boost),
                efficiency_score: 95
            });
        }

        // 5. Final Dispatch
        await updateJobStatus(jobId, 'completed', 100);

        return NextResponse.json(results);

    } catch (error: unknown) {
        const errorMessage = error instanceof Error ? error.message : 'Internal Neural Handshake Failure';
        console.error("Neural Route Error:", error);
        return NextResponse.json({ error: errorMessage }, { status: 500 });
    }
}
